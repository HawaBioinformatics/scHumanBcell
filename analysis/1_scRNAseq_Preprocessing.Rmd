---
title: "Part 1 - QUALITY CONTROL AND PRE-PROCESSING"
output: html_document
---

# downloading the data

In this tutorial, we are going to mainly use Seurat package with publicly available datasets. Extensive tutorials with various contexts can be found in https://satijalab.org/seurat/.

Here, in the first part, we are going to analyze a single cell RNAseq dataset product by 10X Genomics and processed through Cell Ranger(TM) pipeline, which generates barcode count matrices.



# analyze the data in R

### install R packages

now, switch back to R and install the packages we are going to use in this workshop.

```{r eval=FALSE}
#install.packages("tidyverse")
#install.packages("rmarkdown")
#install.packages('Seurat')
```

load the library

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(Seurat)
```

```{r}
# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "/Users/hawacoulibaly/Documents/filtered_feature_bc_matrix")
# Initialize the Seurat object with the raw (non-normalized data).
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k")
pbmc

## getting help
?CreateSeuratObject
```

if you want to know more details of the `Seurat` object, you can learn at https://github.com/satijalab/seurat/wiki

Also check https://satijalab.org/seurat/essential_commands.html for all the commands you can use to interact with Seurat objects.


```{r}
# Lets examine a few B cell marker genes in the first thirty cells
pbmc.data[c("CD19", "CD34", "CD38", "MS4A1"), 1:30]
```

The `.` values in the matrix represent 0s (no molecules detected). Since most values in an scRNA-seq matrix are 0, Seurat uses a sparse-matrix representation whenever possible. This results in significant memory and speed savings for Drop-seq/inDrop/10x data.

### Quality control and filtering cells

```{r}
## check at metadata
meta <- pbmc@meta.data
dim(meta)

# The [[ operator can add columns to object metadata. This is a great place to stash QC stats
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")

# Visualize QC metrics as a violin plot
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), layer = "counts", ncol = 3)
```

we set the cutoff based on the visualization above. The cutoff is quite subjective.

```{r}
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 3000 & percent.mt < 20)
```


visualize cell count after filtering 
```{r}
# Visualize QC metrics as a violin plot
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), layer = "counts", ncol = 3)
```



### Normalization of the data

By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in  `pbmc[["RNA"]]@data`.

Now, Seurat has a new normalization method called `SCTransform`. Check out the tutorial [here](https://satijalab.org/seurat/v3.0/sctransform_vignette.html).

```{r}
pbmc <- NormalizeData(pbmc, normalization.method = "LogNormalize", scale.factor = 10000)
```

### feature selection

```{r}
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(pbmc), 10)

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)

CombinePlots(plots = list(plot1, plot2), ncol =1)
```
### Check for G1, G2, M, AND S PHASES
```{r}
# Cell cycle genes
cc.genes.updated.2019
```

```{r}
# Cell cycle score
s.genes <- cc.genes.updated.2019$s.genes
g2m.genes <- cc.genes.updated.2019$g2m.genes

pbmc <- CellCycleScoring(pbmc, s.features = s.genes, g2m.features = g2m.genes)
table(pbmc[[]]$Phase)
```


### Scaling the data

Scaling is an essential step in the Seurat workflow, but only on genes that will be used as input to PCA. Therefore, the default in  ScaleData is only to perform scaling on the previously identified variable features (2,000 by default). To do this, omit the  features argument in the previous function call


Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData function:

* Shifts the expression of each gene, so that the mean expression across cells is 0
* Scales the expression of each gene, so that the variance across cells is 1.

Think it as standardize the data. center the mean to 0 and variance to 1. `?scale`

This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
* The results of this are stored in `pbmc[["RNA"]]@scale.data`

```{r}
all.genes <- rownames(pbmc)
pbmc <- ScaleData(pbmc, features = all.genes)
pbmc <- ScaleData(pbmc, vars.to.regress = c("percent.mt", "S.Score","G2M.Score"))
```
This can take long for large dataset.

Let's check the data matrix before and after scaling.
```{r}
# raw counts, same as pbmc@assays$RNA@counts[1:6, 1:6]
pbmc[["RNA"]]$counts[1:6, 1:6]

# library size normalized and log transformed data
pbmc[["RNA"]]$data[1:6, 1:6]

# scaled data
pbmc[["RNA"]]$scale.data[1:6, 1:6]
```

### PCA 

Principle component analysis (PCA) is a linear dimension reduction technology.

Highly recommend this 5 min video on PCA by StatQuest https://www.youtube.com/watch?v=HMOI_lkzW08
and two longer versions by the same person:

https://www.youtube.com/watch?v=_UVHneBUBW0  
https://www.youtube.com/watch?v=FgakZw6K1QQ&t=674s

some blog posts I wrote on PCA: 

* [PCA in action](https://divingintogeneticsandgenomics.rbind.io/post/pca-in-action/)
* [permutation test for PCA components](https://divingintogeneticsandgenomics.rbind.io/post/permute-test-for-pca-components/)

```{r}
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc), verbose = FALSE)

p1<- DimPlot(pbmc, reduction = "pca")
p1
```
```{r}
pbmc@reductions$pca
```


### Determine How many PCs to include for downstream analysis

To overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a ‘metafeature’ that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many components should we choose to include? 10? 20? 100?

In Macosko et al, we implemented a resampling test inspired by the JackStraw procedure. We randomly permute a subset of the data (1% by default) and rerun PCA, constructing a ‘null distribution’ of feature scores, and repeat this procedure. We identify ‘significant’ PCs as those who have a strong enrichment of low p-value features.

```{r eval=FALSE}
# NOTE: This process can take a long time for big datasets, comment out for expediency. More
# approximate techniques such as those implemented in ElbowPlot() can be used to reduce
# computation time, takes 10 mins for this dataset
pbmc <- JackStraw(pbmc, num.replicate = 100, dims = 30)
pbmc <- ScoreJackStraw(pbmc, dims = 1:30)

JackStrawPlot(pbmc, dims = 1:30)
```


An alternative heuristic method generates an ‘Elbow plot’: a ranking of principle components based on the percentage of variance explained by each one (ElbowPlot function). In this example, we can observe an ‘elbow’ around PC10-20, suggesting that the majority of true signal is captured in the first 10 PCs.

```{r}
ElbowPlot(pbmc, ndims = 10)
```

### variance explained by each PC

hint from https://github.com/satijalab/seurat/issues/982

```{r}
mat <- pbmc[["RNA"]]$scale.data 
pca <- pbmc[["pca"]]

# Get the total variance:
total_variance <- sum(matrixStats::rowVars(mat))

eigValues = (pca@stdev)^2  ## EigenValues
varExplained = eigValues / total_variance

varExplained %>% enframe(name = "PC", value = "varExplained" ) %>%
  ggplot(aes(x = PC, y = varExplained)) + 
  geom_bar(stat = "identity") +
  theme_classic() +
  ggtitle("scree plot")

### this is what Seurat is plotting: standard deviation
pca@stdev %>% enframe(name = "PC", value = "Standard Deviation" ) %>%
  ggplot(aes(x = PC, y = `Standard Deviation`)) + 
  geom_point() +
  theme_classic()
```

### Cluster the cells

Seurat v3 applies a graph-based clustering approach, building upon initial strategies in (Macosko et al)
Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.

As in PhenoGraph, we first construct a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors function, and takes as input the previously defined dimensionality of the dataset.

To cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The `FindClusters` function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between **0.4-1.2** typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets

```{r}
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- FindClusters(pbmc, resolution = 0.5)
# Look at cluster IDs
table(pbmc[[]]$seurat_clusters)
```

### Run non-linear dimensional reduction (UMAP/tSNE)

Seurat offers several **non-linear** dimensional reduction techniques, such as tSNE and UMAP (as opposed to PCA which is a linear dimensional reduction technique), to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.

t-SNE explained by StatQuest https://www.youtube.com/watch?v=NEaUSP4YerM

```{r}
pbmc <- RunUMAP(pbmc, dims = 1:10)
pbmc<- RunTSNE(pbmc, dims = 1:10)
```


```{r}
## now let's visualize in the UMAP space

p1 <- DimPlot(pbmc, reduction = "umap", label = TRUE, label.size = 6)

## now let's visualize in the TSNE space
p2 <- DimPlot(pbmc, reduction = "tsne", label = TRUE, label.size = 6)

p1+p2
```

### Finding differentially expressed features (cluster biomarkers)

Seurat can help you find markers that define clusters via differential expression. By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.

Finding all marker genes takes long in this step. let's watch the PCA video while Seurat is working hard.

```{r}
# find markers for every cluster compared to all remaining cells, report only the positive ones
pbmc.markers <- FindAllMarkers(pbmc, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
pbmc.markers %>% group_by(cluster) %>% top_n(n = 2, wt = avg_log2FC)
```

### Visualize marker genes

VlnPlot (shows expression probability distributions across clusters), and FeaturePlot (visualizes feature expression on a tSNE or PCA plot) are our most commonly used visualizations. We also suggest exploring RidgePlot, CellScatter, and DotPlot as additional methods to view your dataset.

```{r}
VlnPlot(pbmc, features = c("MS4A1", "CD19"))

## understanding the matrix of data slots
pbmc[["RNA"]]$data[c("MS4A1", "CD19"), 1:30]
pbmc[["RNA"]]$scale.data[c("MS4A1", "CD19"), 1:30]
pbmc[["RNA"]]$counts[c("MS4A1", "CD19"), 1:30]
```

```{r}
# you can plot raw counts as well
VlnPlot(pbmc, features = c("MS4A1", "CD19"), slot = "counts", log = TRUE)
VlnPlot(pbmc, features = c("MS4A1", "CD19"), slot = "scale.data")
```

FeaturePlot.

plot the expression intensity overlaid on the Tsne/UMAP plot.
```{r}
FeaturePlot(pbmc, features = c("MS4A1", "CD19", "ITGAX", "CD72", "CD38", "CD37", "IGHM"), label = TRUE , keep.scale = 'all')
```



There is a package to deal with this type of overplotting problem. https://github.com/SaskiaFreytag/schex

`DoHeatmap` generates an expression heatmap for given cells and features. In this case, we are plotting the top 20 markers (or all markers if less than 20) for each cluster.

```{r}
top10 <- pbmc.markers %>% group_by(cluster) %>% top_n(n = 10, wt = avg_log2FC)
pbmc.markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1.5) %>%
    slice_head(n = 10) %>%
    ungroup() -> top10
DoHeatmap(pbmc, features = top10$gene) + NoLegend()
```

save the Seurat object into a file

```{r}
saveRDS(pbmc, "/Users/hawacoulibaly/Documents/GitHub/scHumanBcellFlu/data/pbmc_3k.RDS")
```
